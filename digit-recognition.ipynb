{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Recognition notebook\n",
    "![MNIST](https://localab.jp/wp-content/uploads/2017/07/MNIST.png)\n",
    "\n",
    "***\n",
    "\n",
    "![Keras](https://s3.amazonaws.com/keras.io/img/keras-logo-2018-large-1200.png)\n",
    "\n",
    "***\n",
    "\n",
    "![MNIST](https://achintavarna.files.wordpress.com/2017/11/mnist_2layers.png?w=634)\n",
    "\n",
    "***\n",
    "\n",
    "**[https://keras.io/](https://keras.io/)**\n",
    "\n",
    "*keras*\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright so! What does that python file digitrec.py actually do? It uses a convolutional nueral network (CNNs) to take in an image specified by the user and it returns what it thinks the image is based off of a model. CNNs have been extremely successful in identifying faces, objects and traffic signs. In this case we are using a CNN to identify a specific number by learning on the MNIST dataset.\n",
    "\n",
    "Intially we are getting the mnist data from keras, splitting it into training data and testing dataset arrays which have 60000 and 10000 images respectly. Each having 28 x 28 pixels.\n",
    "\n",
    "The datasets are 3D arrays. Training dataset shape is (60000, 28, 28) & Testing dataset shape is (10000, 28, 28).\n",
    "\n",
    "The CNN then expects a 4D array which consists of the batch size, height, width and channels (grayscale value of 1). \n",
    "\n",
    "We the scale down the values per pixel by a factor of 255 as each pixel ranges from 0 to 255. This will make the data much easier to deal with.\n",
    "\n",
    "After that we define some global variables:\n",
    "1. number_of_classes:\n",
    "\n",
    "This value represents how many outputs our CNN has, in this case we are reading in 10 different shapes 0 to 9.\n",
    "\n",
    "2. epochs:\n",
    "\n",
    "The amount of times we loop over the data, One Epoch is when an ENTIRE dataset is passed forward and backward through the neural network only ONCE.\n",
    "\n",
    "3. batch_size:\n",
    "\n",
    "Total number of training examples present in a single batch. You canâ€™t pass the entire dataset into the neural net at once. So, you divide dataset into Number of Batches or sets or parts.\n",
    "\n",
    "In this project we are using one-hot encoding, essentially converts all the numbers to a very basic integer binary matrix where the array only contains only one '1' and the rest of the elements are '0'.\n",
    "\n",
    "So the number 5 would be represented as: [0,0,0,0,0,1,0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "import os\n",
    "import sys\n",
    "\n",
    "if os.path.exists('./my_model.h5'):\n",
    "    model = load_model('my_model.h5')\n",
    "else:\n",
    "    # load data\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "    # The Convolutional Neural Networks expects a 4D array\n",
    "    # Reshaping to format which CNN expects (batch, height, width, channels)\n",
    "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1).astype('float32')\n",
    "\n",
    "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1).astype('float32')\n",
    "\n",
    "    # normalize inputs from 0-255 to 0-1\n",
    "    X_train/=255\n",
    "    X_test/=255\n",
    "    # https://hackernoon.com/what-is-one-hot-encoding-why-and-when-do-you-have-to-use-it-e3c6186d008f\n",
    "\n",
    "    # one hot encoding for labels, the only output is a number between 1 and 10 \n",
    "    # eg 5 : [0,0,0,0,0,1,0,0,0,0]\n",
    "\n",
    "    number_of_classes = 10\n",
    "    epochs = 5\n",
    "    batch_size=200\n",
    "\n",
    "    y_train = np_utils.to_categorical(y_train, number_of_classes)\n",
    "    y_test = np_utils.to_categorical(y_test, number_of_classes)\n",
    "\n",
    "    # create Convolutional model\n",
    "    #  http://cs231n.github.io/convolutional-networks/\n",
    "\n",
    "    model = Sequential()\n",
    "    # first layer: 32 filters/ output channels, of size 5 x 5.  input layer expects image of structure height, width and channels\n",
    "    model.add(Conv2D(32, (5, 5), input_shape=(X_train.shape[1], X_train.shape[2], 1), activation='relu'))\n",
    "    # max pooling layer, reduces the over-fitting\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # another hidden layer\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    # last layer, 10 neorons, gives probability of the class, binary classification of specified number.\n",
    "    model.add(Dense(number_of_classes, activation='softmax'))\n",
    "\n",
    "    # prints layer types, the shape of output and parameters. \n",
    "    print(model.summary())\n",
    "\n",
    "    # compile the model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "    # fit the model\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "    metrics = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "    print(metrics)\n",
    "\n",
    "    model.save('my_model.h5')\n",
    "\n",
    "for index in range(10):\n",
    "    img = Image.open('images/' + str(index) + '.png').convert(\"L\")\n",
    "    img = img.resize((28,28))\n",
    "    im2arr = np.array(img)\n",
    "    im2arr = im2arr.reshape(1,28,28,1)\n",
    "    # Predicting the Test set results\n",
    "    y_pred = model.predict_classes(im2arr)\n",
    "    print(y_pred)\n",
    "\n",
    "print('testing a specific image: ')\n",
    "img = Image.open('./images/3.png').convert(\"L\")\n",
    "img = img.resize((28,28))\n",
    "im2arr = np.array(img)\n",
    "im2arr = im2arr.reshape(1,28,28,1)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = model.predict_classes(im2arr)\n",
    "print(y_pred)\n",
    "\n",
    "\n",
    "def testUserImage(fileName):\n",
    "    print('testing a specific image: ')\n",
    "    img = Image.open('./images/' +str(fileName)+ '.png').convert(\"L\")\n",
    "    img = img.resize((28,28))\n",
    "    im2arr = np.array(img)\n",
    "    im2arr = im2arr.reshape(1,28,28,1)\n",
    "    # Predicting the Test set results\n",
    "    y_pred = model.predict_classes(im2arr)\n",
    "    print(y_pred)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    fileName = int(sys.argv[1])\n",
    "    testUserImage(fileName)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
